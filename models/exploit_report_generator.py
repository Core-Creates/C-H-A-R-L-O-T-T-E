# Import the CVE severity prediction model
from models.cve_severity_predictor import predict_severity

# Import your LLM interface to generate the report text
from core.llm_interface import query_llm

def generate_exploit_report(cve_features: list) -> str:
    """
    Generate a short exploit scenario using a language model, based on CVE input features.

    Args:
        cve_features (list of float): Must follow this order:
            [cvss_base, cvss_impact, exploitability_score, is_remote, cwe_id]

    Returns:
        str: A brief AI-generated exploit scenario/report.
    """

    # Predict the severity of the CVE using the pre-trained model
    severity = predict_severity(cve_features)

    # Build a structured prompt for the language model
    prompt = f"""
    You are a cybersecurity analyst. Based on the following CVE data:
    - CVSS Base Score: {cve_features[0]}
    - Impact Score: {cve_features[1]}
    - Exploitability Score: {cve_features[2]}
    - Remote Exploitable: {'Yes' if cve_features[3] else 'No'}
    - CWE ID: {cve_features[4]}
    - Predicted Severity: {severity}

    Write a short exploit scenario (3â€“5 sentences) explaining how an attacker could exploit this vulnerability and what the risks are.
    """

    # Send the prompt to the LLM and return its response
    return query_llm(prompt)
