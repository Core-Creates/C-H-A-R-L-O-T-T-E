# ******************************************************************************************
# exploit_report.py — Merge of LLM-based generator + optional local LSTM decoder
# ******************************************************************************************

from typing import List, Optional

# Import the CVE severity prediction model
from models.cve_severity_predictor import predict_severity

# Import your LLM interface to generate the report text
from core.llm_interface import query_llm

# Optional: local neural text generator (PyTorch)
try:
    import torch
    import torch.nn as nn
except Exception:  # pragma: no cover
    torch = None
    nn = None  # type: ignore

# Order of features expected by both paths
FEATURE_ORDER = [
    "cvss_base",           # float
    "cvss_impact",         # float
    "exploitability_score",# float
    "is_remote",           # bool/int
    "cwe_id",              # int/float (categorical encoded)
]


def _format_llm_prompt(cve_features: List[float], severity: str) -> str:
    return f"""
You are a cybersecurity analyst. Based on the following CVE data:
- CVSS Base Score: {cve_features[0]}
- Impact Score: {cve_features[1]}
- Exploitability Score: {cve_features[2]}
- Remote Exploitable: {'Yes' if cve_features[3] else 'No'}
- CWE ID: {cve_features[4]}
- Predicted Severity: {severity}

Write a short exploit scenario (3–5 sentences) explaining how an attacker could exploit this vulnerability, likely impact, and immediate mitigations.
""".strip()


def generate_exploit_report(
    cve_features: List[float],
    *,
    use_local_model: bool = False,
    local_model: Optional["ExploitReportGenerator"] = None,
    tokenizer: Optional[object] = None,
    max_len: int = 128,
    temperature: float = 1.0,
) -> str:
    """
    Generate a short exploit scenario report from CVE features.

    Args:
        cve_features: Must follow FEATURE_ORDER:
            [cvss_base, cvss_impact, exploitability_score, is_remote, cwe_id]
        use_local_model: If True, try to use a local LSTM decoder instead of the LLM.
        local_model: A trained ExploitReportGenerator instance (required if use_local_model=True).
        tokenizer: Tokenizer with attributes/methods:
            - sos_id (int), eos_id (int), pad_id (int)
            - decode(List[int]) -> str
        max_len: Max tokens to generate with local model.
        temperature: Sampling temperature for local generation (>= 0). If == 0, greedy.

    Returns:
        str: A brief exploit scenario/report.
    """
    # Basic validation
    if len(cve_features) != 5:
        raise ValueError(f"cve_features must be length 5 in order {FEATURE_ORDER}")

    # Predict the severity (used by both paths for consistent framing)
    severity = predict_severity(cve_features)

    # Local model path (optional)
    if use_local_model:
        if torch is None or nn is None:
            raise RuntimeError("PyTorch not available; cannot use local model generation.")
        if local_model is None or tokenizer is None:
            raise ValueError("local_model and tokenizer are required when use_local_model=True.")
        local_model.eval()

        # Prepare feature tensor
        device = next(local_model.parameters()).device
        feats = torch.tensor([cve_features], dtype=torch.float32, device=device)  # (1, 5)

        # Start with <SOS>
        generated = [tokenizer.sos_id]
        hidden = None

        # Initialize hidden from features via encoder_fc
        with torch.no_grad():
            encoder_out = local_model.encoder_fc(feats)  # (1, hidden_dim)
            hidden = encoder_out.unsqueeze(0)            # (1, 1, hidden_dim)
            cell = torch.zeros_like(hidden)

            # First input is <SOS>
            inp = torch.tensor([[tokenizer.sos_id]], dtype=torch.long, device=device)

            for _ in range(max_len):
                emb = local_model.embedding(inp)  # (1,1,emb_dim)
                out, (hidden, cell) = local_model.lstm(emb, (hidden, cell))
                logits = local_model.fc_out(out.squeeze(1))  # (1, vocab_size)

                if temperature and temperature > 0:
                    probs = torch.softmax(logits / temperature, dim=-1)
                    next_tok = torch.multinomial(probs, num_samples=1)  # (1,1)
                else:
                    next_tok = torch.argmax(logits, dim=-1, keepdim=True)  # (1,1)

                tok_id = int(next_tok.item())
                generated.append(tok_id)

                if tok_id == tokenizer.eos_id:
                    break

                inp = next_tok  # feed back

        # Decode to text
        # Strip SOS/EOS/PAD for cleanliness
        toks = [t for t in generated if t not in (tokenizer.sos_id, tokenizer.eos_id, tokenizer.pad_id)]
        text = tokenizer.decode(toks).strip()

        # Prepend a severity line for clarity and parity with LLM path
        return f"[Predicted Severity: {severity}]\n{text}"

    # Default: LLM path (uses severity + rich prompt)
    prompt = _format_llm_prompt(cve_features, severity)
    return query_llm(prompt)


# ──────────────────────────────────────────────────────────────────────────────
# Optional local sequence model (from the 'main' branch content)
# ──────────────────────────────────────────────────────────────────────────────
if nn is not None:

    class ExploitReportGenerator(nn.Module):
        """
        Simple LSTM-based generative model to create textual exploit reports
        from CVE numerical features.

        Inputs:
            - features: tensor of shape (batch_size, feature_dim), e.g., CVE scores
            - target_seq: tokenized sequences of exploit reports during training
            - teacher_forcing_ratio: probability to use ground-truth tokens during training

        Output:
            - logits over vocabulary for each token in the sequence

        Note:
            This is a foundational model. Training on a dataset of (features, report text)
            pairs is required before it can generate meaningful exploit reports.
        """

        def __init__(self, feature_dim=5, embedding_dim=128, hidden_dim=256, vocab_size=1000):
            super().__init__()

            # Encoder: project input features into decoder hidden space
            self.encoder_fc = nn.Sequential(
                nn.Linear(feature_dim, 64),
                nn.ReLU(),
                nn.Linear(64, hidden_dim),
            )

            # Embedding layer to convert token indices to vectors
            self.embedding = nn.Embedding(vocab_size, embedding_dim)

            # LSTM decoder to generate token sequences
            self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)

            # Output layer to produce logits for each vocabulary token
            self.fc_out = nn.Linear(hidden_dim, vocab_size)

        def forward(self, features, target_seq, teacher_forcing_ratio: float = 0.5):
            """
            Training-time forward pass with optional teacher forcing.

            Args:
                features: (batch, feature_dim) float tensor
                target_seq: (batch, seq_len) long tensor of token ids (includes <SOS>)
                teacher_forcing_ratio: float in [0,1]

            Returns:
                logits: (batch, seq_len, vocab_size)
            """
            batch_size, seq_len = target_seq.size()

            # Encode CVE features → initial hidden state
            encoder_output = self.encoder_fc(features)   # (batch, hidden_dim)
            hidden = encoder_output.unsqueeze(0)         # (1, batch, hidden_dim)
            cell = torch.zeros_like(hidden)              # (1, batch, hidden_dim)

            embeddings = self.embedding(target_seq)      # (batch, seq_len, embed_dim)
            outputs = torch.zeros(batch_size, seq_len, self.fc_out.out_features, device=features.device)

            # Decoder input starts with first token (usually <SOS>)
            input_token = embeddings[:, 0, :].unsqueeze(1)  # (batch, 1, embed_dim)

            for t in range(1, seq_len):
                output, (hidden, cell) = self.lstm(input_token, (hidden, cell))  # output: (batch, 1, hidden)
                logits = self.fc_out(output.squeeze(1))                           # (batch, vocab)
                outputs[:, t, :] = logits

                # Decide next input (teacher forcing vs. model prediction)
                if torch.rand(1).item() < teacher_forcing_ratio:
                    next_ids = target_seq[:, t]                                   # (batch,)
                else:
                    next_ids = logits.argmax(dim=1)                               # (batch,)

                input_token = self.embedding(next_ids).unsqueeze(1)               # (batch, 1, embed_dim)

            return outputs


__all__ = ["FEATURE_ORDER", "generate_exploit_report", "ExploitReportGenerator"]

